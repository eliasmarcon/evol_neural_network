{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "folder = \"../input/heart.csv\"  # Replace with the actual path to your CSV file\n",
    "df = pd.read_csv(folder)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1:\n",
      "Weights shape: (13, 64)\n",
      "Biases shape: (64,)\n",
      "\n",
      "Layer 3:\n",
      "Weights shape: (64, 32)\n",
      "Biases shape: (32,)\n",
      "\n",
      "Layer 5:\n",
      "Weights shape: (32, 1)\n",
      "Biases shape: (1,)\n",
      "\n",
      "Epoch 1/50\n",
      "33/33 [==============================] - 1s 1ms/step - loss: 0.6709 - accuracy: 0.5522\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7337\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.8263\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.8537\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.8702\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.8820\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.8790\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.8898\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.8917\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.8907\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.8907\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.8917\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.9024\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.4095 - accuracy: 0.9015\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3965 - accuracy: 0.8976\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3932 - accuracy: 0.8985\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3808 - accuracy: 0.9044\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.9005\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3665 - accuracy: 0.9034\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.9132\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3400 - accuracy: 0.9151\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.9151\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.9122\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.9132\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.9141\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3135 - accuracy: 0.9190\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3111 - accuracy: 0.9220\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3129 - accuracy: 0.9180\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.3042 - accuracy: 0.9151\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2959 - accuracy: 0.9220\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 0s 969us/step - loss: 0.2967 - accuracy: 0.9239\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2901 - accuracy: 0.9249\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 0s 972us/step - loss: 0.2797 - accuracy: 0.9317\n",
      "Epoch 34/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2800 - accuracy: 0.9278\n",
      "Epoch 35/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2679 - accuracy: 0.9376\n",
      "Epoch 36/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2677 - accuracy: 0.9376\n",
      "Epoch 37/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2593 - accuracy: 0.9415\n",
      "Epoch 38/50\n",
      "33/33 [==============================] - 0s 972us/step - loss: 0.2712 - accuracy: 0.9298\n",
      "Epoch 39/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.9473\n",
      "Epoch 40/50\n",
      "33/33 [==============================] - 0s 1000us/step - loss: 0.2497 - accuracy: 0.9395\n",
      "Epoch 41/50\n",
      "33/33 [==============================] - 0s 971us/step - loss: 0.2511 - accuracy: 0.9395\n",
      "Epoch 42/50\n",
      "33/33 [==============================] - 0s 971us/step - loss: 0.2440 - accuracy: 0.9424\n",
      "Epoch 43/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2421 - accuracy: 0.9385\n",
      "Epoch 44/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.9444\n",
      "Epoch 45/50\n",
      "33/33 [==============================] - 0s 970us/step - loss: 0.2404 - accuracy: 0.9424\n",
      "Epoch 46/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2284 - accuracy: 0.9512\n",
      "Epoch 47/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2383 - accuracy: 0.9405\n",
      "Epoch 48/50\n",
      "33/33 [==============================] - 0s 941us/step - loss: 0.2334 - accuracy: 0.9346\n",
      "Epoch 49/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2348 - accuracy: 0.9327\n",
      "Epoch 50/50\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.2131 - accuracy: 0.9541\n",
      "Trained Weights and Biases:\n",
      "Layer 1:\n",
      "Weights shape: (13, 64)\n",
      "Weights values:\n",
      "[[ 4.51962091e-02  2.73452014e-01 -4.81207930e-02  6.43354356e-02\n",
      "   2.07306385e-01 -4.06901026e-03 -3.17777246e-02  9.20584276e-02\n",
      "  -9.44679156e-02 -1.19338119e-02 -7.94221610e-02  3.07652522e-02\n",
      "  -1.13167182e-01  1.45076036e-01 -3.04638688e-02 -8.21302682e-02\n",
      "  -4.87438217e-02  3.14277858e-02  1.55811921e-01  5.79506792e-02\n",
      "   3.81664326e-03 -8.67229700e-02  1.37244850e-01 -1.48609327e-02\n",
      "   6.32130206e-02 -2.52938122e-02 -4.78583090e-02 -1.50856346e-01\n",
      "   1.04585782e-01 -1.42382100e-01 -7.97246862e-03  1.27194915e-02\n",
      "  -7.82572478e-02  2.61115236e-03 -1.61559299e-01 -6.34550452e-02\n",
      "   1.02679685e-01  2.00743861e-02  8.71803612e-02 -1.19963676e-01\n",
      "   7.47663826e-02 -9.29917395e-02 -2.83052661e-02  9.55225527e-02\n",
      "  -1.43212855e-01  9.30333659e-02  1.06427945e-01 -1.19243730e-02\n",
      "  -8.90336335e-02 -9.41314548e-02  3.74386720e-02  6.57779872e-02\n",
      "   8.74946713e-02  1.26424283e-01  9.20886695e-02  8.78811255e-03\n",
      "  -6.03580847e-02 -2.46794075e-02 -7.76475295e-02  7.31575582e-03\n",
      "   1.15648761e-01 -1.31823584e-01 -2.02839132e-02  2.91471444e-02]\n",
      " [ 9.41310376e-02  1.02607571e-01 -2.19992157e-02 -7.89835975e-02\n",
      "  -7.81200379e-02  6.93531781e-02  1.51034705e-02  7.69175142e-02\n",
      "  -8.66705924e-03 -2.50959434e-02  1.54362665e-03 -1.14727467e-01\n",
      "  -2.66932626e-03 -1.95201095e-02 -5.76625206e-02 -2.00302258e-01\n",
      "   1.07110031e-01 -3.03245168e-02 -6.13644011e-02 -1.43319041e-01\n",
      "   3.73578370e-02 -9.34771597e-02  1.87699541e-01  9.44195539e-02\n",
      "  -1.20143369e-01 -1.96777314e-01  8.83810688e-03 -9.09195766e-02\n",
      "   2.23687105e-02 -1.62910357e-01  8.26299638e-02 -1.50368556e-01\n",
      "   2.06117183e-02 -1.04702776e-02  5.51186465e-02 -3.84769551e-02\n",
      "   2.27149818e-02  2.22600594e-01  1.24860324e-01 -3.77846509e-02\n",
      "   5.22252396e-02  8.39573983e-03  6.06508926e-02  6.08658828e-02\n",
      "  -7.58077726e-02  5.56731299e-02 -1.48596436e-01 -4.28823978e-02\n",
      "  -1.06983304e-01 -1.31176323e-01 -8.59469101e-02  2.79276110e-02\n",
      "  -9.98959914e-02  1.33383229e-01 -4.92789820e-02 -1.35799751e-01\n",
      "   3.33312876e-03 -2.02717371e-02  3.33694778e-02  2.47713784e-03\n",
      "   1.49130866e-01 -5.13723865e-03 -1.22096904e-01 -1.26765847e-01]\n",
      " [-9.44671631e-02 -7.09907636e-02 -1.13372855e-01 -1.94258541e-01\n",
      "   6.92205057e-02 -1.47697181e-01 -5.16176894e-02 -1.48082137e-01\n",
      "  -8.52640122e-02 -1.21404886e-01 -3.27339023e-02  2.42373407e-01\n",
      "  -5.63308224e-02  3.23017463e-02 -1.17722385e-01 -3.52729335e-02\n",
      "  -1.07457051e-02 -3.53451222e-02 -1.99336573e-01  6.83759227e-02\n",
      "   3.05216033e-02 -1.91737294e-01 -1.68483406e-01  8.45324472e-02\n",
      "   1.28274830e-02  5.98009564e-02  1.18077964e-01  1.62695184e-01\n",
      "   2.34061908e-02  6.35329075e-03 -1.97460651e-01  1.16351753e-01\n",
      "  -4.28480208e-02  5.61605440e-03 -1.15261219e-01 -2.61368930e-01\n",
      "  -4.05258639e-03 -8.08898583e-02  4.74160388e-02 -2.28016842e-02\n",
      "   1.58914439e-02 -1.28111556e-01 -1.12690888e-01  6.92722797e-02\n",
      "   1.03093565e-01 -1.10030517e-01 -1.47418212e-02  1.73869371e-01\n",
      "  -2.09585294e-01  4.48984280e-02  3.35024223e-02  1.37814119e-01\n",
      "   2.42723208e-02  7.05934241e-02 -2.56410372e-02  9.45483223e-02\n",
      "   4.71675061e-02  3.69204730e-02  6.87595503e-03  7.01145316e-03\n",
      "  -1.59259319e-01  8.15567821e-02  8.06388482e-02  1.00356624e-01]\n",
      " [ 4.51905765e-02 -2.68903691e-02  1.29684746e-01  7.80553073e-02\n",
      "  -1.93377268e-02 -4.25031073e-02  7.35109746e-02  4.47548926e-03\n",
      "   2.25803815e-02  1.16985030e-02  2.79995613e-02  7.21003786e-02\n",
      "   1.40449470e-02 -5.22161163e-02  8.10755417e-02 -3.46545391e-02\n",
      "  -2.03740411e-02 -8.93050954e-02  6.78457618e-02 -3.39855179e-02\n",
      "   1.00276567e-01  1.63326904e-01 -6.08495548e-02  2.79471129e-02\n",
      "  -9.01637897e-02 -6.66218176e-02  1.39893563e-02  7.20340759e-02\n",
      "  -5.73012792e-02 -1.81336049e-02 -6.44527450e-02 -3.59862782e-02\n",
      "  -6.76640496e-02 -4.61938642e-02 -1.39463961e-01  2.36422345e-01\n",
      "  -6.62659556e-02 -4.44692746e-02 -8.99013784e-03  4.11670562e-03\n",
      "   8.29211101e-02  7.16554075e-02 -1.14833981e-01 -3.01874708e-02\n",
      "   2.86371429e-02  1.79884080e-02  2.78100022e-03  4.89200912e-02\n",
      "   1.33397505e-01 -8.99710692e-03 -1.06864244e-01  4.68726903e-02\n",
      "  -3.07633542e-02  3.11119650e-02  4.74399328e-03  3.64136347e-03\n",
      "   4.81999405e-02  8.86789784e-02  1.20281890e-01 -1.39464736e-01\n",
      "   7.36820651e-03  8.47431347e-02  9.92390513e-02 -6.38804734e-02]\n",
      " [ 2.58437991e-02 -3.90026160e-03  1.30509183e-01 -8.69854018e-02\n",
      "  -1.06631294e-01 -5.59392609e-02 -5.13289915e-03  2.91633010e-02\n",
      "   1.68661010e-02  1.31524593e-01 -2.25431360e-02 -5.80903329e-03\n",
      "   5.27438112e-02 -3.46246883e-02  1.46252990e-01  1.98862534e-02\n",
      "  -6.41957372e-02 -5.13145328e-02 -1.00492090e-01 -2.36510057e-02\n",
      "  -3.30639295e-02 -2.24761739e-02  3.36775277e-03  6.31658360e-02\n",
      "  -6.72879145e-02  8.91644284e-02  6.33763056e-03 -1.18594982e-01\n",
      "   9.58571211e-02  5.53983310e-03 -9.15367231e-02  3.01931743e-02\n",
      "  -2.42824629e-02  2.53862906e-02  1.89028978e-02 -6.33169562e-02\n",
      "  -1.30788852e-02 -6.93416074e-02  4.64494713e-02  8.96048099e-02\n",
      "   3.55723053e-02  2.58213896e-02 -4.54351248e-04  4.57243901e-03\n",
      "  -1.00912917e-02  2.77138371e-02  2.00836957e-01  5.11121899e-02\n",
      "  -1.74902026e-02  6.27742410e-02  5.49472719e-02  2.08875607e-03\n",
      "   2.15319209e-02 -2.66405214e-02 -1.15814358e-01  3.83337773e-02\n",
      "  -1.12927318e-01  1.07008871e-02 -2.49833688e-02  2.04648823e-01\n",
      "   3.76446284e-02  6.63418556e-03 -9.73960236e-02  4.73823845e-02]\n",
      " [ 5.85184917e-02  6.26355112e-02  1.00214161e-01  1.07774608e-01\n",
      "   1.65593298e-03  2.69519333e-02  2.74490435e-02 -5.75959589e-03\n",
      "   5.61023876e-02  1.08382322e-01  3.66184413e-02  4.55820523e-02\n",
      "   1.03487030e-01 -9.96262580e-03  1.58248499e-01 -5.80332763e-02\n",
      "  -1.84720054e-01  4.92738672e-02  1.07235149e-01  4.68521528e-02\n",
      "   6.04316033e-02  5.12921214e-02  1.29627526e-01 -6.40538037e-02\n",
      "   4.95505221e-02 -1.79551579e-02  1.35441363e-01  6.36880994e-02\n",
      "   8.04230720e-02 -5.09608984e-02 -1.51944712e-01  5.00464812e-03\n",
      "  -1.58347294e-01  4.93460931e-02 -1.19117178e-01  5.10441512e-02\n",
      "   7.22097009e-02 -3.73059660e-02  1.16323210e-01  1.36185050e-01\n",
      "   1.03324577e-01  1.80532932e-02  4.56192270e-02  7.11937472e-02\n",
      "  -1.31870136e-01 -6.58230111e-03 -1.78543940e-01  2.96386182e-02\n",
      "   6.15304485e-02 -1.41800672e-01 -1.67589828e-01  1.14352249e-01\n",
      "   1.94849949e-02  2.41728295e-02 -3.27297710e-02 -1.04548976e-01\n",
      "   8.01554397e-02 -2.06591766e-02 -1.54202998e-01  5.46594076e-02\n",
      "  -3.33480686e-02 -1.34881064e-01 -7.63961673e-02 -6.60038590e-02]\n",
      " [ 5.66803254e-02 -2.55243510e-01  3.06216460e-02 -6.78683147e-02\n",
      "  -1.71834096e-01 -4.36368212e-02  2.28904132e-02 -1.59740880e-01\n",
      "   8.66079330e-02 -5.22729643e-02  5.69558255e-02  2.28939280e-02\n",
      "   7.38418847e-02 -1.19354188e-01 -2.26277914e-02  4.32549678e-02\n",
      "  -9.56398994e-02 -2.35172119e-02 -7.62866139e-02  8.29273313e-02\n",
      "   6.69137165e-02 -4.02677394e-02 -2.24798381e-01 -8.61585736e-02\n",
      "  -3.31581235e-02  9.16421339e-02  1.62923858e-01 -1.98152497e-01\n",
      "  -2.25464161e-02  1.14258684e-01 -2.31189638e-01 -1.55763581e-01\n",
      "  -1.01833612e-01 -1.66696701e-02 -5.24427444e-02  5.65009266e-02\n",
      "  -4.35086787e-02 -3.41521241e-02  1.55962184e-01  6.51078001e-02\n",
      "   1.62125677e-01 -1.23803444e-01 -1.87728480e-02  3.41154262e-02\n",
      "   1.58607692e-01 -1.98944882e-01  2.92959344e-02  1.82585958e-02\n",
      "  -1.09617271e-01 -2.79698789e-01 -2.70649076e-01  1.48857355e-01\n",
      "   8.48636106e-02  6.18176833e-02 -7.94232488e-02 -1.98665336e-01\n",
      "   1.58990338e-01 -6.24574861e-03  9.14924815e-02 -6.69196397e-02\n",
      "  -2.79603094e-01  8.62896815e-02  7.41661415e-02 -2.06447035e-01]\n",
      " [-1.06635131e-02 -7.02014193e-03  8.82377401e-02  7.56051391e-02\n",
      "  -4.46748957e-02  2.13836171e-02 -1.62774194e-02  1.05731145e-01\n",
      "  -4.94490638e-02 -3.09443213e-02 -2.39818580e-02  4.60230485e-02\n",
      "  -1.54359594e-01  6.67722076e-02  1.74585113e-03  7.02340081e-02\n",
      "  -1.17597818e-01  1.12818643e-01  1.37113497e-01  1.00219138e-01\n",
      "   6.52734712e-02  1.11839637e-01 -1.76410042e-02 -1.07867746e-02\n",
      "   7.68501386e-02  1.00969024e-01  2.21717777e-03 -1.77938659e-02\n",
      "   9.83464569e-02 -3.94760352e-03  1.27070293e-01  7.93041587e-02\n",
      "  -6.21786714e-02 -5.69315478e-02 -1.85137596e-02  1.28341660e-01\n",
      "  -4.15646136e-02 -1.11577086e-01 -1.01955989e-02 -1.48630157e-01\n",
      "   8.97403881e-02 -9.35871452e-02  2.81089712e-02 -5.73426969e-02\n",
      "  -9.00145769e-02  1.64147019e-01  1.57820463e-01  2.06466645e-01\n",
      "   4.70414273e-02  9.13874879e-02  4.90501337e-02 -1.25123248e-01\n",
      "   1.21015534e-01 -5.69199473e-02 -1.21580929e-01 -3.71913202e-02\n",
      "  -1.48107737e-01  4.42341454e-02 -1.32557213e-01 -4.16321084e-02\n",
      "   1.50369152e-01 -1.78330004e-01  2.99638938e-02  4.82632928e-02]\n",
      " [ 1.60991341e-01 -5.08066593e-03  2.37694800e-01  1.03473686e-01\n",
      "   6.25340268e-02  5.63775338e-02  9.61279497e-02 -1.14169292e-01\n",
      "   1.22667700e-01  2.73021888e-02  9.89218056e-02  2.15133298e-02\n",
      "   3.27154212e-02  1.36481673e-01  1.19274057e-01  8.34136158e-02\n",
      "  -9.13116559e-02  1.75268911e-02  1.34192944e-01 -2.18796935e-02\n",
      "   5.23211248e-02  7.19191805e-02 -1.96215302e-01 -9.71949920e-02\n",
      "   6.15437329e-03 -1.77181046e-02  5.06313480e-02  1.18326813e-01\n",
      "   2.06226304e-01  5.65080643e-02  1.73064228e-02  2.39775740e-02\n",
      "  -1.00773327e-01  1.20054886e-01 -4.16012667e-02  1.72839493e-01\n",
      "   1.01311736e-01 -1.04092471e-01  1.08445413e-01  8.40581432e-02\n",
      "   2.00520426e-01 -1.46443462e-02  1.05050102e-01  9.91607904e-02\n",
      "   5.27913384e-02 -3.65192033e-02 -1.46240249e-01  6.51715100e-02\n",
      "   6.07566535e-03 -1.10074274e-01 -4.56846952e-02  1.74322441e-01\n",
      "  -2.95624696e-02  3.84327956e-02  5.11815399e-02  1.18625034e-02\n",
      "   1.39848799e-01 -4.08822671e-03  6.08310010e-03  2.44920179e-02\n",
      "  -3.01990565e-03  1.68286506e-02  4.94206361e-02  5.87465568e-03]\n",
      " [ 3.15721519e-02 -1.38306739e-02  5.63815460e-02 -2.63869241e-02\n",
      "   1.04060406e-02  5.58326617e-02  1.26634926e-01 -1.98653843e-02\n",
      "   1.42135486e-01  1.04330303e-02  7.67056420e-02 -4.83542271e-02\n",
      "   7.33075738e-02  9.59222838e-02  2.69433837e-02  1.05782516e-01\n",
      "   2.45672576e-02  2.82366332e-02 -4.10609355e-05 -9.97425690e-02\n",
      "   7.93690011e-02 -2.42213849e-02  1.27993701e-02  1.41252398e-01\n",
      "   1.48304878e-03 -3.16867866e-02 -1.28072947e-01  3.02125346e-02\n",
      "   1.36244863e-01  9.47070420e-02  7.41772875e-02  7.19598681e-02\n",
      "   3.90823893e-02  1.81486294e-01  1.54855162e-01  9.02029276e-02\n",
      "  -5.39528728e-02  1.09154180e-01  1.13292314e-01  9.17298794e-02\n",
      "   1.34386674e-01  3.98159213e-03  2.00268075e-01 -2.05429077e-01\n",
      "   7.60085061e-02 -6.84052333e-03  3.55338678e-02 -1.98613163e-02\n",
      "   2.52815932e-02  1.49844036e-01  1.51995569e-01 -2.66280770e-01\n",
      "  -6.71548396e-02 -1.01491675e-01  1.11439079e-02  8.92007947e-02\n",
      "   1.20536774e-01  1.00420132e-01  8.75627715e-03  2.69073364e-03\n",
      "  -8.64951871e-03  3.63129787e-02  1.29844785e-01  3.35200690e-02]\n",
      " [-9.94449258e-02 -4.72086109e-02 -3.75803523e-02 -1.20894186e-01\n",
      "   1.07289087e-02 -3.18761468e-02 -5.19890189e-02  8.31074044e-02\n",
      "  -7.18856603e-02 -1.15615748e-01 -5.40098585e-02  3.39768469e-01\n",
      "  -6.04509078e-02 -1.64234021e-03 -1.00090936e-01  3.61564308e-02\n",
      "   6.63173422e-02  1.78396832e-02 -1.69225514e-01  1.11296818e-01\n",
      "  -5.62167093e-02 -7.41221234e-02  6.41135946e-02  7.18895793e-02\n",
      "   1.13436446e-01  1.37375921e-01  3.80783305e-02 -1.35528482e-02\n",
      "  -1.59725975e-02  3.93984839e-02  2.32769474e-02  2.36667860e-02\n",
      "   7.14968294e-02  4.21219356e-02  3.05669513e-02 -6.37919307e-02\n",
      "   1.30348936e-01  6.05798028e-02 -3.71914841e-02 -3.97134479e-03\n",
      "  -9.44033638e-03  7.84249753e-02 -2.12913956e-02  7.42939934e-02\n",
      "  -9.08747688e-02  6.06234409e-02 -1.56549569e-02  6.71060607e-02\n",
      "   1.29165146e-02 -4.64815907e-02 -6.25004321e-02  7.26782382e-02\n",
      "   1.20019697e-01  9.76065174e-02  5.55344447e-02  1.58343643e-01\n",
      "   3.19280569e-03 -3.86011973e-02 -8.29036683e-02 -5.17531857e-02\n",
      "   9.44156870e-02 -1.04825363e-01 -2.87961829e-02  9.11493227e-03]\n",
      " [ 4.74360734e-02  7.31676295e-02  9.64887813e-02  7.94894770e-02\n",
      "   2.52980050e-02  4.44930680e-02  3.56899276e-02  3.63555476e-02\n",
      "   1.31079825e-02  2.76451129e-02  1.66109148e-02 -1.24799825e-01\n",
      "  -4.66176420e-02  2.98151691e-02  1.44579653e-02 -8.75227712e-03\n",
      "  -2.74460651e-02 -3.16038013e-01  1.01938859e-01 -4.42178786e-01\n",
      "  -4.21303026e-02  5.79448827e-02  3.33892442e-02 -2.06546113e-02\n",
      "  -4.74172503e-01  3.18183377e-02  1.94611236e-01 -2.40090489e-01\n",
      "   7.06425309e-02 -3.19561325e-02  8.63539726e-02 -3.85909289e-01\n",
      "  -3.93270254e-02  4.46882769e-02  1.69614572e-02  1.25579432e-01\n",
      "  -3.54479551e-01  8.09311960e-03  1.27661712e-02 -4.33702543e-02\n",
      "   7.55767897e-02  7.38692731e-02  4.41548740e-03 -2.76739180e-01\n",
      "  -9.86839086e-02  6.27912655e-02 -1.48974150e-01  4.99035940e-02\n",
      "   5.99851646e-02 -2.37050116e-01 -2.93220937e-01  1.97832197e-01\n",
      "  -4.02617246e-01 -3.37801456e-01 -2.64512952e-02 -3.09387237e-01\n",
      "   2.66657062e-02 -2.97159608e-02 -1.21178471e-01 -4.40628603e-02\n",
      "   8.73815641e-02 -1.10502154e-01 -5.23717441e-02 -3.48460287e-01]\n",
      " [-4.61564995e-02 -8.27621073e-02 -4.80911182e-03 -2.55864505e-02\n",
      "  -3.54888327e-02 -3.04826535e-02  2.52711903e-02  3.50319445e-02\n",
      "   2.91861501e-02 -1.05826132e-01 -2.28163600e-03 -8.40331987e-02\n",
      "   4.72601354e-02  4.55175899e-02 -7.64386132e-02  2.87731647e-01\n",
      "   1.43385068e-01 -3.97060700e-02 -1.49301989e-02 -9.61456969e-02\n",
      "   7.19458461e-02  1.05513837e-02 -8.97516757e-02  2.01363444e-01\n",
      "  -7.63605833e-02 -6.92737773e-02  8.42843950e-02  9.80323367e-03\n",
      "  -7.54879788e-02  2.13697642e-01  7.44033232e-02 -1.57675207e-01\n",
      "   1.79178640e-01 -1.15147866e-01  5.14505357e-02  4.66020852e-02\n",
      "  -2.16424989e-04 -1.70442939e-01 -1.79361373e-01 -6.19975524e-03\n",
      "  -1.18297517e-01  1.29958108e-01  2.57137604e-02  5.72623871e-03\n",
      "   8.12814906e-02  6.24100044e-02 -1.13813974e-01 -1.44059937e-02\n",
      "   1.23729199e-01 -2.01987103e-01 -2.14602992e-01  6.82422668e-02\n",
      "  -1.04896516e-01  1.46134011e-02  1.43739954e-01 -1.28280923e-01\n",
      "  -8.64539444e-02  1.69480398e-01  1.67276099e-01  7.46566877e-02\n",
      "   2.74259746e-02  1.07229531e-01  1.88505366e-01 -1.49610788e-01]]\n",
      "Biases shape: (64,)\n",
      "Biases values:\n",
      "[-1.08031027e-01 -1.28085971e-01 -1.13463283e-01 -1.58127978e-01\n",
      " -6.13806844e-02  6.77594822e-03  1.94070190e-02 -2.95782741e-02\n",
      " -2.44137906e-02 -8.74589533e-02 -2.61706598e-02 -5.11371754e-02\n",
      " -2.06410456e-02 -5.49960919e-02 -1.29453301e-01 -1.02631330e-01\n",
      "  1.44090682e-01 -6.74284473e-02 -1.89693645e-01 -4.26125601e-02\n",
      "  5.71895353e-02 -3.84236723e-02 -1.49037838e-02  1.93942022e-02\n",
      " -4.23165523e-02  3.42898741e-02 -2.80996889e-01 -1.65431276e-01\n",
      " -7.97435865e-02 -7.47836083e-02 -4.67841607e-03 -5.22365235e-02\n",
      "  6.54142871e-02  4.00838554e-02 -1.07997498e-02 -1.68841869e-01\n",
      " -5.87240793e-03 -2.13467907e-02 -1.47528902e-01 -3.05605810e-02\n",
      " -1.50780112e-01 -1.00697037e-02  7.81976525e-03 -8.94948468e-02\n",
      " -9.73539874e-02  5.12206025e-05 -7.00455606e-02 -1.66618302e-02\n",
      " -6.57376274e-02 -1.69951528e-01 -2.29470000e-01 -2.02843636e-01\n",
      " -9.49240178e-02 -7.68320262e-02 -4.69233878e-02 -1.77634209e-02\n",
      " -1.00726828e-01  3.65199298e-02  2.45573390e-02  2.29938049e-02\n",
      "  3.62763293e-02 -4.51497175e-02  4.47205687e-03 -1.00729845e-01]\n",
      "\n",
      "Layer 3:\n",
      "Weights shape: (64, 32)\n",
      "Weights values:\n",
      "[[ 0.02727727  0.05023047  0.07050177 ...  0.06611963  0.02037811\n",
      "   0.06000617]\n",
      " [ 0.21520357  0.14762498  0.11775494 ...  0.19460513  0.1222274\n",
      "   0.10887522]\n",
      " [ 0.26091376  0.22407685  0.23941466 ...  0.16162482  0.15123446\n",
      "   0.17037302]\n",
      " ...\n",
      " [ 0.1180582   0.15910769  0.04291688 ...  0.15757078  0.12954879\n",
      "   0.18094294]\n",
      " [ 0.07153495  0.11513819  0.14061642 ...  0.16676575  0.15366758\n",
      "   0.08746357]\n",
      " [-0.18506509 -0.2554755  -0.18026271 ... -0.25603688 -0.23378928\n",
      "  -0.21969995]]\n",
      "Biases shape: (32,)\n",
      "Biases values:\n",
      "[0.02858771 0.02464778 0.03100026 0.0201574  0.01629486 0.01778858\n",
      " 0.02541308 0.0039233  0.01679462 0.04161694 0.01789418 0.03421313\n",
      " 0.0295339  0.01750602 0.02119646 0.01334707 0.01377008 0.00846\n",
      " 0.02138182 0.00842399 0.0197666  0.01704319 0.01746561 0.03748984\n",
      " 0.02819466 0.02481867 0.02503021 0.01929271 0.02876186 0.01452891\n",
      " 0.01162486 0.01865203]\n",
      "\n",
      "Layer 5:\n",
      "Weights shape: (32, 1)\n",
      "Weights values:\n",
      "[[-0.3461568 ]\n",
      " [-0.43333578]\n",
      " [-0.41327408]\n",
      " [-0.34639624]\n",
      " [-0.376741  ]\n",
      " [-0.31255952]\n",
      " [-0.41248092]\n",
      " [-0.36243013]\n",
      " [-0.43582433]\n",
      " [-0.4564413 ]\n",
      " [-0.35463452]\n",
      " [-0.62218654]\n",
      " [-0.39169902]\n",
      " [-0.33690614]\n",
      " [-0.31743616]\n",
      " [-0.3994127 ]\n",
      " [-0.44359604]\n",
      " [-0.41810635]\n",
      " [-0.3155415 ]\n",
      " [-0.31850627]\n",
      " [-0.70486766]\n",
      " [-0.42218268]\n",
      " [-0.3994366 ]\n",
      " [-0.4240947 ]\n",
      " [-0.3855332 ]\n",
      " [-0.44293332]\n",
      " [-0.3705792 ]\n",
      " [-0.33455613]\n",
      " [-0.4076681 ]\n",
      " [-0.301539  ]\n",
      " [-0.4005229 ]\n",
      " [-0.41340816]]\n",
      "Biases shape: (1,)\n",
      "Biases values:\n",
      "[1.2513026]\n",
      "\n",
      "Ranges of Trained Weights:\n",
      "Layer 1 weight range: (-0.4741725, 0.33976847)\n",
      "Layer 1 biases range: (-0.2809969, 0.14409068)\n",
      "Layer 3 weight range: (-0.33572024, 0.3643504)\n",
      "Layer 3 biases range: (0.0039232974, 0.041616943)\n",
      "Layer 5 weight range: (-0.70486766, -0.301539)\n",
      "Layer 5 biases range: (1.2513026, 1.2513026)\n",
      "33/33 [==============================] - 0s 817us/step - loss: 0.1991 - accuracy: 0.9610\n",
      "Test Accuracy: 0.9609755873680115\n"
     ]
    }
   ],
   "source": [
    "# Define constant arrays for weight initialization using RandomNormal\n",
    "mean = 0\n",
    "stddev = 0.05\n",
    "\n",
    "big_array_layer1 = np.random.normal(loc=mean, scale=stddev, size=(13, 64))\n",
    "big_array_layer2 = np.random.normal(loc=mean, scale=stddev, size=(64, 32))\n",
    "big_array_output = np.random.normal(loc=mean, scale=stddev, size=1)\n",
    "\n",
    "# Build the neural network model with weight initialization from the big arrays\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],), kernel_initializer=Constant(value=big_array_layer1)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation='relu', kernel_initializer=Constant(value=big_array_layer2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='sigmoid', kernel_initializer=Constant(value=big_array_output)))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the shapes of the weights and biases\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if i % 2 == 0:\n",
    "        weights, biases = layer.get_weights()\n",
    "        print(f\"Layer {i + 1}:\")\n",
    "        print(f\"Weights shape: {weights.shape}\")\n",
    "        print(f\"Biases shape: {biases.shape}\")\n",
    "        print()\n",
    "        \n",
    "    \n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y, epochs=50, batch_size=32)\n",
    "\n",
    "# Print the shapes of the weights and biases after training\n",
    "print(\"Trained Weights and Biases:\")\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if i % 2 == 0:\n",
    "        weights, biases = layer.get_weights()\n",
    "        print(f\"Layer {i + 1}:\")\n",
    "        print(f\"Weights shape: {weights.shape}\")\n",
    "        print(f\"Weights values:\\n{weights}\")\n",
    "        print(f\"Biases shape: {biases.shape}\")\n",
    "        print(f\"Biases values:\\n{biases}\")\n",
    "        print()\n",
    "\n",
    "# Print the ranges of the trained weights after training\n",
    "print(\"Ranges of Trained Weights:\")\n",
    "for i, layer in enumerate(model.layers):\n",
    "    if i % 2 == 0:\n",
    "        weights, biases = layer.get_weights()\n",
    "        weight_range = (np.min(weights), np.max(weights))\n",
    "        biases_range = (np.min(biases), np.max(biases))\n",
    "        print(f\"Layer {i + 1} weight range: {weight_range}\")\n",
    "        print(f\"Layer {i + 1} biases range: {biases_range}\")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_train_scaled, y)\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
